from scraper import BigVul
import json

obj = BigVul("bigvul.csv")
print(obj.getItem(0).keys())
print(json.dumps(obj.getItem(0), indent=4))
# obj.getItem(0).full_content contains the full content of the last file in the commit

data = []
for i in range(1, 10):
    data.append(obj.getItem(i))
with open("data.json", "w") as f:
    json.dump(data, f, indent=4)