from openai import OpenAI
import os
import re
import json

from utils import chat

class Generator423:
    def __init__(self, apiKey, directory="423"):
        self.client = OpenAI(api_key=apiKey)
        self.directory = directory
        self.totalCost = 0

    def _removeComments(self, code):
        code = re.sub(r"/\*.*?\*/", "", code, flags=re.DOTALL)
        code = re.sub(r"//.*?$", "", code, flags=re.MULTILINE)
        code = re.sub(r'\s+$', '', code, flags=re.MULTILINE)
        return code

    def _part1(self, vulnerabilityName, vulnerabilityDesc, code):
        system = """
            You are a data augmenter. You are creating a dataset of vulnerable code. 

            Your responses should follow the template:
            === PART 1 ===
            <Explanation of where the vulnerability currently is>
            === PART 2 === 
            <Explanation with 3 short parts that specifically reference parts of the code, the first being what you will add, the second what you will change, and the third what you will remove>
            <This part should avoid any changes related to the vulnerability>
            === PART 3 ===
            ```
            <The new full code function with comments showing how it was changed>
            ```

        """
        prompt = f"""
            Below is a C code function, it is already vulnerable to: {vulnerabilityName} {vulnerabilityDesc}.
            You need to provide a variation of the code to help augment the dataset with variations. 
            Keep the vulnerable code intact, do not change the function signature or parameters, and do not add any new vulnerabilities.
            Add, change and remove some code to create a new variation.
            Do not make any changes related to the vulnerability. Keep it there. Do not add anything to prevent it. 
            The changes you make should be unrelated to the vulnerability.

            {code}
        """
        response, cost = chat(self.client, prompt, system=system)
        #print(response)
        self.totalCost += cost
        # remove comments
        response = self._removeComments(response)
        return response, system, prompt

    def generateCodeSnippet(self, vulnerabilityName, vulnerabilityDesc, code, uid=None):
        retries = 0
        codeSnippet = None
        system = ""
        prompt = ""
        while retries < 3:
            response, system, prompt = self._part1(vulnerabilityName, vulnerabilityDesc, code)
            codeSnippet = re.search(r"=== PART 1 ===.*?=== PART 2 ===.*?=== PART 3 ===.*?```.*?\n(.*?)```", response, re.DOTALL)
            if codeSnippet is None:
                print("error34")
                print(response)
                retries += 1
                continue
            codeSnippet = codeSnippet.group(1)
            if len(codeSnippet) < 0.5*len(code):
                print("error49")
                print(response)
                retries += 1
                continue
            if re.sub(r'[^a-zA-Z]', '', self._removeComments(code)) == re.sub(r'[^a-zA-Z]', '', self._removeComments(codeSnippet)):
                print("error53")
                retries += 1
                continue
            break
        if retries == 3:
            print("FAILED")
            return

        output = {
            "cwe": vulnerabilityName,
            "prompt": {
                "system": system,
                "user": prompt
            },
            "response": response,
            "code": codeSnippet,
            "uid": uid
        }

        _directory = f"{self.directory}"
        os.makedirs(_directory, exist_ok=True)
        # if file already exists, increment name
        i = 1
        while os.path.exists(f"{_directory}/{vulnerabilityName}-{i}.json"):
            i += 1
        with open(f"{_directory}/{vulnerabilityName}-{i}.json", "w") as file:
            file.write(json.dumps(output, indent=4))
    