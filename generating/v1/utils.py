from openai import OpenAI


def chat(client, user, system="", temperature=1):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": system,
            },
            {
                "role": "user",
                "content": user
            }
        ],
        temperature=temperature,
        stop=[],
    )
    return response.choices[0].message.content, (0.15/1000000 * response.usage.prompt_tokens + 0.6/1000000 * response.usage.completion_tokens)


def chat4o(client, user, system="", temperature=1):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": system,
            },
            {
                "role": "user",
                "content": user
            }
        ],
        temperature=temperature,
        stop=[],
    )
    return response.choices[0].message.content, (5/1000000 * response.usage.prompt_tokens + 15/1000000 * response.usage.completion_tokens)