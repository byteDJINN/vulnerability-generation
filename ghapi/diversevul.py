import json
import requests
import os
import time
from dotenv import load_dotenv
from datetime import datetime

load_dotenv()

GH_TOKEN = os.getenv("GH_TOKEN")  # GitHub API token

# GitHub API endpoint for searching commits
headers = {
    "Accept": "application/vnd.github+json",
    "Authorization": f"Bearer {GH_TOKEN}",
    "X-GitHub-Api-Version": "2022-11-28"
}

seen = set()
c = 0
output = {}

data = []
with open("../input/diversevul.json", "r") as f:
    for fline in f:
        data.append(json.loads(fline))

with open("diversevul_context1.json", "a") as f:  # Open file in append mode
    while c < len(data):
        line = data[c]
        try:
            if line['commit_id'] in seen:
                c += 1
                continue
            
            url = f"https://api.github.com/search/commits?per_page=1&q=hash:{line['commit_id']}"
            response = requests.get(url, headers=headers).json()
            repo = response['items'][0]['repository']['full_name']
            parentHash = response['items'][0]['parents'][0]['sha']
            url = f"https://api.github.com/repos/{repo}/commits/{line['commit_id']}"
            response = requests.get(url, headers=headers).json()
            rawURLs = [x['raw_url'] for x in response['files']]
            rawURLs = [x.replace(line['commit_id'], parentHash) for x in rawURLs]
            output[line['commit_id']] = rawURLs

            f.write(json.dumps({line['commit_id']: rawURLs}, indent=4) + "\n")
            f.flush()  # Ensure data is written to file

            seen.add(line['commit_id'])
            c += 1
            time.sleep(2)

            # print progress percentage
            if c % 10 == 0:
                prog = (c / len(data)) * 100
                print(f"{prog:.2f}%", end="\r")

        except Exception as e:
            print(f"{datetime.now()}: An error occurred. Retrying in 30 seconds...")
            print(e)
            c -= 1
            time.sleep(30)
