{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "\n",
    "gpt4o = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "gpt35 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open gpt-3.5-turbo/NONE_SINGLE_SEMANTIC_responses.json\n",
    "\n",
    "data = []\n",
    "for root, dirs, files in os.walk(\"gpt-3.5-turbo\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\"_responses.json\"):\n",
    "            with open(os.path.join(root, file)) as f:\n",
    "                _ = json.load(f)\n",
    "                data.extend(_[\"vulnerable\"])\n",
    "                data.extend(_[\"safe\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "Input tokens: 8015.369647943223\n",
      "Output tokens: 117.18316057337628\n",
      "gpt-4o\n",
      "Input tokens: 8079.88242984545\n",
      "Output tokens: 117.34678059485455\n",
      "gpt-3.5-turbo\n",
      "Input cost: 0.0040076848239716115\n",
      "Output cost: 0.00017577474086006442\n",
      "gpt-4o\n",
      "Input cost: 0.04039941214922725\n",
      "Output cost: 0.001760201708922818\n"
     ]
    }
   ],
   "source": [
    "totalInputTokens = [0,0]\n",
    "totalOutputTokens = [0,0]\n",
    "\n",
    "# count the number of tokens in the input and output\n",
    "for d in data:\n",
    "    totalInputTokens[0] += len(gpt35.encode(d[\"prompt\"]))\n",
    "    totalOutputTokens[0] += len(gpt35.encode(d[\"llm_detection\"][0]))\n",
    "    totalInputTokens[1] += len(gpt4o.encode(d[\"prompt\"]))\n",
    "    totalOutputTokens[1] += len(gpt4o.encode(d[\"llm_detection\"][0]))\n",
    "\n",
    "# print the averages\n",
    "print(\"gpt-3.5-turbo\")\n",
    "print(\"Input tokens:\", totalInputTokens[0]/len(data))\n",
    "print(\"Output tokens:\", totalOutputTokens[0]/len(data))\n",
    "print(\"gpt-4o\")\n",
    "print(\"Input tokens:\", totalInputTokens[1]/len(data))\n",
    "print(\"Output tokens:\", totalOutputTokens[1]/len(data))\n",
    "\n",
    "# print pricing 4o is 5/1million input and 15/1million output\n",
    "# 3.5 is 0.5/1million input and 1.5/1million output\n",
    "# print average pricing\n",
    "\n",
    "print(\"gpt-3.5-turbo\")\n",
    "print(\"Input cost:\", totalInputTokens[0]/len(data)*0.5/1000000)\n",
    "print(\"Output cost:\", totalOutputTokens[0]/len(data)*1.5/1000000)\n",
    "print(\"gpt-4o\")\n",
    "print(\"Input cost:\", totalInputTokens[1]/len(data)*5/1000000)\n",
    "print(\"Output cost:\", totalOutputTokens[1]/len(data)*15/1000000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
